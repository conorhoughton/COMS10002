\documentclass[11pt,a4paper]{scrartcl}
\typearea{12}
\usepackage{graphicx}
\usepackage{pstricks}
\usepackage{listings}
\lstset{language=C}
\pagestyle{headings}
\markright{COMS11600 - Principles of programming II.1}
\begin{document}

\subsection*{II.1 Recursion}

A process is recursive if it repeats itself in a self-similar way. An
easy example is the factorial
\begin{equation}
n!=n(n-1)(n-2)\ldots 1
\end{equation}
where $n$ is multiplied by $n-1$ and then by $n-2$ and so on down to one; or, put another way
\begin{equation}
n!=n(n-1)!
\end{equation}
and $1!=1$.

In computer science recursion refers to an approach where a problem is
solved by breaking it up into smaller similar problems. In practise
this often means solving a problem using a function that calls
itself. An easy example of recursion is given by the factorial; see
Table~\ref{c_factorial} or, for a fancier version
Table~\ref{c_factorial_fancy}. You will have learned that recursion is
often a good way to implement algorithms on computers, that many
algorithms can be designed recursively and that this is usually the
best way to program them. Being comfortable with recursion is one of
the signs of, and benefits of, learning to program properly!

A recursive function consists of two parts, a \lq{}base case\rq{},
what happens normally, here return n*factorial(n-1), and a
\lq{}terminating condition\rq{}, a set of cases that the algorithm
will always arrive at and can deal with without calling itself. These
are important to avoid infinite recursion.

The factorial also provides a convenient example for discussing tail
recursion. One problem with recursion is that it can be wasteful of
stack memory; if you call factorial(10) the program will write
factorial(10), factorial(9) and so on down to factorial(1) onto the
stack before factorial(1) returns and the open functions get rolled
back. This isn't really a problem here, the factorial function will
reach values well beyond the capacity of int long long before the
memory use on the stack becomes a problem; however, in other
circumstances it might be a problem. The solution is tail recursion.

\begin{table}[b]
\begin{lstlisting}[numbers=left]
int factorial(int n)
{
   if(n<2)
      return 1;

   return n*factorial(n-1);
}

\end{lstlisting}
\caption{The recursive function for calculating $n!=n(n-1)\ldots 1$. If n<2 it returns 1, giving a terminating condition, it also means $0!=1$ which is a normal mathematical convention, otherwise it calls factorial(n-1). If you trying using this function, note that for even modest values of n, n! is too big to fit into int.\label{c_factorial}}
\end{table}




\begin{table}
\begin{lstlisting}[numbers=left]
int factorial(int n)
{
   return (n<2) ? 1 : n*factorial(n-1);
}

\end{lstlisting}
\caption{A fancier version of the factorial program which uses the ternary operator described in Table~\ref{c_ternary}.\label{c_factorial_fancy}}
\end{table}


\begin{table}
\begin{lstlisting}[numbers=left]
if (a)
   ans=b;
else 
   ans=c;
\end{lstlisting}
\caption{The ternary operator ans = a \& b : c evaluates a and then
  does either sets ans=b or ans=c depending on whether a is true of
  false.  Thus ans=a \& b : c is equivalent to the code above. Ternary
  operators are often faster to execute than the corresponding if
  statement.\label{c_ternary}}
\end{table}

An algorithm is tail recursive if the return value of the function
does not have to be modified before it is returned. The factorial
function in Table~\ref{c_factorial} is not tail recursive because
factorial(n-1) is multiplied by n before it is returned. However, the
version in Table~\ref{c_factorial_tail} is tail recursive, it manages
this by passing around another variable called big\_n that holds the
part of the factorial that is calculated so far. Now, when
factorial(10), for example, is called it will call factorial(10,1),
since $10>2$ this will call factorial(9,10); the only thing remaining
for factorial(10,1) to do is to return the value of factorial(9,10)
when it is done. This means, with a bit of cunning, the function does
not have to remain written on the stack, the compiler just has to know
that whatever factorial(9,10) returns should be sent to whatever
called factorial(10); modern compilers are capable of this cunning so
tail recursive algorithms make more efficient use of stack memory.

\begin{table}
\begin{lstlisting}[numbers=left]
int factorial_r(int n, int big_n)
{
  if(n<2)
    return big_n;

  return factorial_r(n-1,n*big_n);
}

int factorial(int n)
{
  return factorial_r(n,1);
}
\end{lstlisting}
\caption{The tail recursive function for calculating $n!=n(n-1)\ldots
  1$. If n<2 it returns big\_n, otherwise it calls
  factorial(n-1,n*big\_n). Since nothing happens to the
  factorial(n-1,n*big\_n) before it is itself returned, this is an
  example of tail recursion.\label{c_factorial_tail}}
\end{table}

Since you have already learned about recursion, this was all by way of
revision; our task here is to calculate the algorithmic complexity of
recursive algorithms. For simplicity we will not worry about tail
recursion, though in practise, calculating the complexity for
algorithms with tail recursion is no harder. 

The trick is to work out a recursive formula for $T(n)$, the run
time. Consider the factorial example; here
\begin{equation}
T(n)=c+T(n-1)
\end{equation}
where $c$ is a constant representing the computational time required
for factorial(n) itself, the if statement, the multiplication and so
on. Now we can expand it out
\begin{equation}
T(n)=c+[c+T(n-2)=2c+T(n-2)
\end{equation}
and this keeps going
\begin{equation}
T(n)=2c+T(n-2)=3c+T(n-3)=4c+T(n-4)=\ldots = (n-1)c+T(1)
\end{equation}
so factorial is $O(n)$.

We have already seen another recursive algorithm, although we didn't
write it as one: binary search. A recursive version of binary search is
given in Table~\ref{c_binary_search_recursive}. Here, leaving out
rounding effects and so on, in the worst case
\begin{equation}
T(n)=c+T(n/2)
\end{equation}
which is solved by 
\begin{equation}
T(n)=c\log_2(n)
\end{equation}
because 
\begin{equation}
T(n/2)=c\log_2(n/2)=c\log_2(n)-c\log_2(2)=c\log_2(n)-c
\end{equation}
and so, substituting back into the equation, this is the solution.
Here, again, working out the run time requires that you know how to
solve the recursion relation. Our approach here is to do what we have
been doing, we guess, based on the examples we've studied, and then
show we are correct by substituting back in.

\begin{table}
\begin{lstlisting}[numbers=left]
int search(int a[],int n, int val)
{
  return find_r(a,n,val,0,n-1);
}
 
int find_r(int a[],int n, int val,int low,int high)
{

  if(high<low)
    return -1;

  int mid=(high+low)/2;

  if(a[mid]==val)
    return mid;

  if(val>a[mid])
    return find_r(a,n,val,mid+1,high);
  
  return find_r(a,n,val,low,mid-1);
}
\end{lstlisting}
\caption{A recursive implementation of binary search. There are two
  halting conditions, val is found, or high<low, meaning that val
  isn't an element of a. Note that, though each call works with a
  smaller and smaller number of elements, for convenience the same
  array is used each time. This function is implemented in {\tt
    binary\_search\_recursive}.\label{c_binary_search_recursive}}
\end{table}

\end{document}
